---
title: "Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning"
collection: publications
permalink: /publication/2015-10-01-paper-title-number-3
excerpt: 'Medical Large Vision-Language Models (Med-LVLMs) often exhibit suboptimal attention distribution on visual inputs, leading to hallucinated or inaccurate outputs. Existing mitigation methods primarily rely on inference-time interventions, which are limited in attention adaptation or require additional supervision. To address this, we propose A3Tune, a novel fine-tuning framework for Automatic Attention Alignment Tuning. A3Tune leverages zero-shot weak labels from SAM, refines them into prompt-aware labels using BioMedCLIP, and then selectively modifies visually-critical attention heads to improve alignment while minimizing interference. Additionally, we introduce a A3MoE module, enabling adaptive parameter selection for attention tuning across diverse prompts and images. Extensive experiments on medical VQA and report generation benchmarks show that A3Tune outperforms state-of-the-art baselines, achieving enhanced attention distributions and performance in Med-LVLMs.'
date: 2025-07-29
venue: 'ACL 2025'
paperurl: 'https://aclanthology.org/2025.acl-long.460.pdf'
citation: 'Chang, Aofei, Le Huang, Alex James Boyd, Parminder Bhatia, Taha Kass-Hout, Cao Xiao, and Fenglong Ma. (2025). &quot;Focus on what matters: Enhancing medical vision-language models with automatic attention alignment tuning.&quot; <i>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics</i>. 1: 9357â€“9372.'
---

[Download paper here](http://linnabrown.github.io/files/2025.acl-long.460.pdf)

Recommended citation: Chang, Aofei, <b>Le Huang</b>, Alex James Boyd, Parminder Bhatia, Taha Kass-Hout, Cao Xiao, and Fenglong Ma. (2015). "Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning" <i>ACL 2025</i>. 1(3).
